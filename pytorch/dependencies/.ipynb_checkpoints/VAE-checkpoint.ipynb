{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os, sys\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sys.path.append('dependencies/')\n",
    "import Loss\n",
    "import Model\n",
    "import Sampling\n",
    "import Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.nn.init as init\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cuda = torch.cuda.is_available()\n",
    "h_dims = [200]\n",
    "z_dim = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "flatten_bernoulli = lambda img: transforms.ToTensor()(img).view(-1).bernoulli()\n",
    "mnist = datasets.MNIST('../data/', train=True, transform=flatten_bernoulli, download=True)\n",
    "mnist_val = datasets.MNIST('../data/', train=False, transform=flatten_bernoulli, download=True)\n",
    "\n",
    "unlabelled = torch.utils.data.DataLoader(mnist, batch_size=100, shuffle=True, num_workers=2)\n",
    "validation = torch.utils.data.DataLoader(mnist_val, batch_size=100, shuffle=True, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vae = Model.VAE([28*28, h_dims, z_dim]).cuda()\n",
    "if cuda: vae = vae.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "objective = Loss.VariationalInference(Loss.binary_cross_entropy, Loss.KL_divergence_normal)\n",
    "opt = torch.optim.Adam(vae.parameters(), lr = 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10, loss:147.240\n",
      "Epoch: 20, loss:123.000\n",
      "Epoch: 30, loss:97.601\n",
      "Epoch: 40, loss:89.882\n",
      "Epoch: 50, loss:89.191\n",
      "Epoch: 60, loss:84.881\n",
      "Epoch: 70, loss:83.219\n",
      "Epoch: 80, loss:70.545\n",
      "Epoch: 90, loss:73.234\n",
      "Epoch: 100, loss:73.861\n"
     ]
    }
   ],
   "source": [
    "trainer = Trainer.VAE_trainer(vae, objective, opt, cuda)\n",
    "trainer.train(None, unlabelled, 100+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from Plotutils import latent_imshow\n",
    "# %matplotlib inline\n",
    "# latent_imshow(-10, 10, 25, vae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, dims, dataset='mnist'):\n",
    "        super(Classifier, self).__init__()\n",
    "        [z_dim, h_dim, n_class] = dims\n",
    "        neurons = [z_dim, *h_dim, n_class]\n",
    "        linear_layers = [nn.Linear(neurons[i-1], neurons[i]) for i in range(1, len(neurons))]\n",
    "        self.h = nn.ModuleList(modules=linear_layers)\n",
    "        self.output = nn.Linear(dims[-1], n_class)\n",
    "    \n",
    "    def forward(self, z):\n",
    "        for i, next_layer in enumerate(self.h):\n",
    "            z = next_layer(z)\n",
    "            if i < len(self.h) - 1:\n",
    "                z = F.relu(z)\n",
    "        return F.softmax(self.output(z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Classifier_trainer(nn.Module):\n",
    "    def __init__(self, model, classifier, cuda):\n",
    "        super(Classifier_trainer, self).__init__()\n",
    "        self.model = model\n",
    "        self.classifier = classifier\n",
    "        self.cuda = cuda\n",
    "        self.optimizer = torch.optim.Adam(self.classifier.parameters(), lr = 1e-3)\n",
    "        if self.cuda:\n",
    "            self.model = self.model.cuda()\n",
    "            self.classifier = self.classifier.cuda()\n",
    "    \n",
    "    def _calculate_z(self, x):\n",
    "        _, (z, _, _) = self.model(x)\n",
    "        return z\n",
    "    \n",
    "    def _calculate_logits(self, z):\n",
    "        logits = self.classifier(z)\n",
    "        return logits\n",
    "    \n",
    "    def train(self, train_loader, validation_loader, n_epochs):\n",
    "        for epoch in range(n_epochs):\n",
    "            for trn_x, trn_y in train_loader:\n",
    "                trn_x, trn_y = Variable(trn_x), Variable(trn_y)\n",
    "                if self.cuda:\n",
    "                    trn_x, trn_y = trn_x.cuda(), trn_y.cuda()\n",
    "                logits = self._calculate_logits(self._calculate_z(trn_x))\n",
    "                loss = F.cross_entropy(logits, trn_y)\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "                self.optimizer.zero_grad()\n",
    "            if (epoch+1)%10==0:\n",
    "                accuracy = []\n",
    "                for val_x, val_y in validation_loader:\n",
    "                    val_x = Variable(val_x)\n",
    "                    if self.cuda:\n",
    "                        val_x = val_x.cuda()\n",
    "                        val_y = val_y.cuda()\n",
    "                    logits=self._calculate_logits(self._calculate_z(val_x))\n",
    "                    _, val_y_pred = torch.max(logits, 1)\n",
    "                    accuracy += [torch.mean((val_y_pred.data == val_y).float())]\n",
    "                    \n",
    "                print(\"Epoch: {0:} loss: {1:.3f}, accuracy: {2:.3f}\".format(epoch+1, loss.data[0], np.mean(accuracy)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "classifier = Model.Classifier([32,[32],10], dataset='mnist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10 loss: 1.517, accuracy: 0.943\n",
      "Epoch: 20 loss: 1.509, accuracy: 0.955\n",
      "Epoch: 30 loss: 1.515, accuracy: 0.952\n",
      "Epoch: 40 loss: 1.497, accuracy: 0.954\n",
      "Epoch: 50 loss: 1.527, accuracy: 0.959\n"
     ]
    }
   ],
   "source": [
    "classifier_trainer = Trainer.Classifier_trainer(vae, classifier, cuda)\n",
    "classifier_trainer.train(unlabelled, validation, 50+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
